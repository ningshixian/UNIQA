{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aurelio-labs/cookbook/blob/main/information-retrieval/sentence-transformers/v3-fine-tuning.ipynb) [![Open nbviewer](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/nbviewer-shield.svg)](https://nbviewer.org/github/aurelio-labs/cookbook/blob/main/information-retrieval/sentence-transformers/v3-fine-tuning.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune Embedding Models with Sentence Transformers 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this blog post, we will walk through the process of fine-tuning embedding models using Sentence Transformers 3 to enhance Retrieval-Augmented Generation (RAG) performance.\n",
    "\n",
    "## Install the Necessary Libraries\n",
    "Install the following libraries:\n",
    "- Pytorch\n",
    "- Sentence Transformers (HF)\n",
    "- Transformers (HF)\n",
    "- Datasets (HF)\n",
    "\n",
    "We are currently using Python 3.11.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerate launch –multi-gpu –num_processes=2 v4_ft_embedding.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!source activate agent\n",
    "!pip install --q \\\n",
    "    \"torch==2.6.0\" \\\n",
    "    \"sentence-transformers\" \\\n",
    "    \"datasets==2.19.1\"  \\\n",
    "    \"transformers\" \\\n",
    "    \"accelerate\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After installing the necessary libraries, you should register on [Hugging Face](https://huggingface.co/join) as we are going to use Hugging Face Hub to push our models and training logs.\n",
    "\n",
    "Get your access token [here](https://huggingface.co/settings/tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1527805df74535b8e63b0eec98660e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Log into your HF account and store your token (access key) on the disk\n",
    "# from huggingface_hub import login\n",
    "\n",
    "# # login(token=\"ADD YOUR TOKEN HERE\", add_to_git_credential=True)\n",
    "# login(token=\"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\", add_to_git_credential=False)\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "from huggingface_hub import interpreter_login\n",
    "\n",
    "notebook_login()\n",
    "# interpreter_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_API_KEY\"]= \"e7ed666bc81a0db87a16f40b0055262deaac80b0\"\n",
    "os.environ[\"WANDB_PROJECT\"] = \"Fine-tune model with Sentence Transformer\"\n",
    "os.environ[\"WANDB_NAME\"] = \"ft-with-st-v3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"models/stella-fine-tuned-v4.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation\n",
    "\n",
    "The Hugging Face Hub has a lot of datasets that can be used to fine-tune embeddings models.You can take a look [here](https://sbert.net/docs/sentence_transformer/dataset_overview.html) at what sort of dataset structure should your dataset follow in order to be able to use it for fine-tunning embeddings.\n",
    "\n",
    "We are going to use [enelpol/rag-mini-bioasq](https://huggingface.co/datasets/enelpol/rag-mini-bioasq), which includes 4,719 question-answer passages from the BioASQ challenges on biomedical semantic indexing and question answering (QA) [dataset for task b BioASQ11](http://participants-area.bioasq.org/datasets/), which can be used as *Positive Pair* configuration.\n",
    "\n",
    "We have to load the dataset, and we can do it using the HF datasets library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load dataset from HF hub\n",
    "\n",
    "# (anchor, positive, negative)\n",
    "all_nli_triplet_train = load_dataset(\"neulab/conala\", \"triplet\", split=\"train[:500]\", cache_dir=\"./dataset\")\n",
    "# (sentence1, sentence2) + score\n",
    "stsb_pair_score_train = load_dataset(\"sentence-transformers/stsb\", split=\"train[:500]\", cache_dir=\"./dataset\")\n",
    "\n",
    "# (anchor, positive, negative)\n",
    "all_nli_triplet_dev = load_dataset(\"sentence-transformers/all-nli\", \"triplet\", split=\"dev[:400]\", cache_dir=\"./dataset\")\n",
    "# (sentence1, sentence2, score)\n",
    "stsb_pair_score_dev = load_dataset(\"sentence-transformers/stsb\", split=\"validation[:400]\", cache_dir=\"./dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载自定义FAQ数据集，并通过 in-batch 和 hard-negtive-sampling 策略生成负样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6494 unique queries out of 89816 total queries.\n",
      "Found an average of 13.831 positives per query.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a0a25f4279a441ca2d3277d0d8237e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/699 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10769d3f3efc419bb2625c5b8d26056b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying FAISS index: 100%|██████████| 1/1 [01:39<00:00, 99.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric       Positive       Negative     Difference\n",
      "Count          89,816         93,685               \n",
      "Mean           0.8957         0.6806         0.2093\n",
      "Median         0.9107         0.6904         0.2056\n",
      "Std            0.0723         0.0679         0.0843\n",
      "Min            0.1593         0.3519        -0.3537\n",
      "25%            0.8568         0.6395         0.1540\n",
      "50%            0.9107         0.6904         0.2056\n",
      "75%            0.9503         0.7327         0.2611\n",
      "Max            1.0000         0.7946         0.6310\n",
      "Skipped 183,610 potential negatives (55.44%) due to the relative_margin of 0.05.\n",
      "Skipped 9,918 potential negatives (6.72%) due to the max_score of 0.8.\n",
      "Could not find enough negatives for 355395 samples (79.14%). Consider adjusting the range_max, range_min, relative_margin and max_score parameters if you'd like to find more valid negatives.\n"
     ]
    }
   ],
   "source": [
    "# Mine hard negatives\n",
    "# https://github.com/UKPLab/sentence-transformers/releases/tag/v3.1.0\n",
    "# pip install sentence-transformers[train]==3.1.1\n",
    "# RuntimeError: The NVIDIA driver on your system is too old\n",
    "from sentence_transformers.util import mine_hard_negatives\n",
    "def hard_negtive_sampling(dataset):\n",
    "    dataset = mine_hard_negatives(\n",
    "        dataset=dataset,\n",
    "        model=model,\n",
    "        range_min=10,\n",
    "        range_max=50,\n",
    "        max_score=0.8,  # 负样本的最高相似得分，可用于控制难易程度\n",
    "        relative_margin=0.05,         # 0.05 means that the negative is at most 95% as similar to the anchor as the positive\n",
    "        num_negatives=5,  # 10 or less is recommended\n",
    "        sampling_strategy=\"random\",      # \"top\" means that we sample the top candidates as negatives\n",
    "        batch_size=128,        # Adjust as needed\n",
    "        use_faiss=True,               # Optional: Use faiss/faiss-gpu for faster\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "# 加载自定义数据集\n",
    "import pandas as pd\n",
    "custom_samples = pd.read_csv(\n",
    "    \"processed_crm_similar_pair.csv\", \n",
    "    header=0, sep=\",\", encoding=\"utf-8\", index_col=False\n",
    ")\n",
    "from datasets import Dataset\n",
    "custom_dataset = Dataset.from_dict({\n",
    "    \"anchor\": custom_samples['standard_question'],\n",
    "    \"positive\": custom_samples['similar_question'],\n",
    "})\n",
    "\n",
    "custom_dataset = hard_negtive_sampling(custom_dataset)\n",
    "# (anchor, positive, negative)\n",
    "\n",
    "# 切分训练集和测试集\n",
    "custom_dataset = custom_dataset.train_test_split(test_size=0.1, seed=123, shuffle=True)\n",
    "custom_dataset_train = custom_dataset[\"train\"]\n",
    "custom_dataset_dev = custom_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anchor': ['蓝牙名称是什么？',\n",
       "  '保险杠有什么用？',\n",
       "  '什么是珍珠漆？',\n",
       "  '如何确认端到端VLM报名是否成功？',\n",
       "  '车身高度随速调节是什么功能？',\n",
       "  '中控屏可以在行驶时播放视频吗？',\n",
       "  'IMEI是什么？',\n",
       "  '实拍星环是有光斑的，星环大灯的帧率是1/300秒是不是每次拍照星环灯都会频闪？',\n",
       "  '车辆的节能模式开启后车辆的哪些功能会关闭或禁用？',\n",
       "  '账号管理怎么进入？',\n",
       "  '车辆开启空调后多长时间可以出热风？',\n",
       "  '副驾单人充气床垫是否适配L6',\n",
       "  '如何设置上车后不自动展开后视镜?',\n",
       "  '在外面加装踏板是否会影响车辆上牌？',\n",
       "  '在理想汽车中心购买轮胎后，可以享受什么保障？',\n",
       "  '用车服务包购买后是否可以申请退款？',\n",
       "  '屏幕怎么打开？屏幕会自动点亮吗？',\n",
       "  'PM2.5快速净化风速控制逻辑？',\n",
       "  '车辆播报导航信息时，播放的多媒体音量会发生变化吗？',\n",
       "  '车辆车顶的激光雷达如何清洗？'],\n",
       " 'positive': ['如何查看汽车的蓝牙设备名称？',\n",
       "  '保险杠在车辆行驶中的主要功能是什么?',\n",
       "  '你知道吗？有种漆叫珍珠漆，它的光泽是怎么做到的？',\n",
       "  '提交端到端VLM万人团的申请后，如何得知报名结果?',\n",
       "  '我的车能根据速度自动调整车身高度吗？',\n",
       "  '开车时，中控屏能播放电影吗？',\n",
       "  '如何找到我设备的IMEI识别码？',\n",
       "  '星环灯在镜头里老闪，是不是因为它的帧率设置？',\n",
       "  '节能模式下，音响系统会有什么变化？',\n",
       "  '怎么才能找到账号管理？',\n",
       "  '在寒冷的早晨，理想电动车空调需要多长时间才能让车内变暖?',\n",
       "  '请问L6适配的充气床垫型号？',\n",
       "  '在车机上如何设定不自动展开后视镜?',\n",
       "  '外部加装踏板，对新车上牌有无影响？',\n",
       "  '理想汽车中心售出的轮胎，有无额外的客户保障?',\n",
       "  '购车后购买的服务包，我还能申请退款吗?',\n",
       "  '车辆解锁后，仪表盘和中控屏会自动打开吗？',\n",
       "  '当PM2.5过高时，如何让汽车自动提高风速净化?',\n",
       "  '播放音乐时导航有语音，会自动减小音乐声吗?',\n",
       "  '清洗车顶激光雷达时应避免什么？'],\n",
       " 'negative': ['在App里怎么给车辆的蓝牙起个新名字?',\n",
       "  '我刚入手新车，左侧拨杆是控制什么的？',\n",
       "  '汽车厂商如何确保纯色漆的色彩饱和度？',\n",
       "  '参加过6.2的活动，能否继续报名新的端到端测试?',\n",
       "  '开启便捷上下后，车停稳悬架何时会变回原设定?',\n",
       "  '开车时，有没有自动保存视频的功能?',\n",
       "  '车机SIM认证成功，为何App里的车辆列表没变化?',\n",
       "  '星环式灯组的动态熄灭效果是如何表现的?',\n",
       "  '想调整能源模式，它们对续航和动力有什么影响？',\n",
       "  '换了个号码，如何在理想汽车APP里切换登录账号?',\n",
       "  '理想汽车的空调有哪些出风位置?',\n",
       "  '咱们帐篷可以不连车单独使用吗',\n",
       "  '如何控制我的汽车电子后视镜？',\n",
       "  '加装踏板是否会影响质保？店里是否能提供加装服务？',\n",
       "  '我想了解一下轮胎的质量保证覆盖了哪些情况？',\n",
       "  '在理想商城购买的商品退了，退款通常要等多久?',\n",
       "  '车辆行驶时，怎么让副驾驶的屏幕自动显示？',\n",
       "  '车辆如何在行驶时保持尾气清洁?',\n",
       "  '理想汽车的音量控制，能否分别调节语音和媒体?',\n",
       "  '下雪时，车辆的激光雷达系统需要特殊维护吗？']}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_dataset_train[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all datasets into a dictionary with dataset names to datasets\n",
    "train_dataset = {\n",
    "    \"all-nli-triplet\": all_nli_triplet_train,\n",
    "    \"stsb\": stsb_pair_score_train,\n",
    "    \"custom\": custom_dataset_train\n",
    "}\n",
    "\n",
    "eval_dataset = {\n",
    "    \"all-nli-triplet\": all_nli_triplet_dev,\n",
    "    \"stsb\": stsb_pair_score_dev, \n",
    "    \"custom\": custom_dataset_dev\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model evaluator that will be used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "from sentence_transformers import evaluation\n",
    "\n",
    "model_evaluator = evaluation.TripletEvaluator(\n",
    "    anchors=eval_dataset['custom'][\"anchor\"],\n",
    "    positives=eval_dataset['custom'][\"positive\"],\n",
    "    negatives=eval_dataset['custom'][\"negative\"],\n",
    "    name=\"all_nli_dev\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss function that will be used for training\n",
    "\n",
    "In this case, we are using the MultipleNegativesRankingLoss to fine-tune our embedding model. This choice is based on our dataset format, which consists of positive text pairs. You can take a look at [dataset format](https://sbert.net/docs/sentence_transformer/training_overview.html#dataset-format) information and [loss function](https://sbert.net/docs/sentence_transformer/loss_overview.html) information to determine which loss function to use based on your use case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.losses import CoSENTLoss, MultipleNegativesRankingLoss\n",
    "\n",
    "# (anchor, positive), (anchor, positive, negative)\n",
    "mnrl_loss = MultipleNegativesRankingLoss(model)\n",
    "\n",
    "# (sentence_A, sentence_B) + score\n",
    "cosent_loss = CoSENTLoss(model)\n",
    "\n",
    "# Create a mapping with dataset names to loss functions, so the trainer knows which loss to apply where.\n",
    "losses={\n",
    "    \"all-nli-triplet\": mnrl_loss,\n",
    "    \"stsb\": cosent_loss,\n",
    "    \"custom\": mnrl_loss,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune embedding model with SentenceTransformersTrainer\n",
    "\n",
    "Now that we've prepared our data and model, we're ready to fine-tune our embedding model using the SentenceTransformersTrainer.\n",
    "\n",
    "To configure our training process, we'll use the SentenceTransformerTrainingArguments class. This tool allows us to specify various parameters that can impact training performance and help with tracking and debugging. We'll be using parameter values based on those recommended in the [Sentence Transformers documentation](https://sbert.net/docs/sentence_transformer/training_overview.html#training-arguments). However, it's important to note that these are just starting points. For optimal results, you should experiment with different values tailored to your specific dataset and task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Currently using DataParallel (DP) for multi-gpu training, while DistributedDataParallel (DDP) is recommended for faster training. See https://sbert.net/docs/sentence_transformer/training/distributed.html for more information.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainingArguments\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "\n",
    " \n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    # Required parameter:\n",
    "    output_dir=os.getenv(\"WANDB_NAME\"), # Save checkpoints\n",
    "    # Optional training parameters:\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=True,   # Loading model in mixed-precision\n",
    "    bf16=False,  # Set to True if you have a GPU that supports BF16\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # losses that use \"in-batch negatives\" benefit from no duplicates\n",
    "    # Optional tracking/debugging parameters:\n",
    "    eval_strategy=\"steps\",  # transformers 版本 4.41.0 中引入的\n",
    "    eval_steps=500,         # 每隔多少步的训练进行一次验证(执行evaluator)\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,   # save checkpoints during training\n",
    "    save_total_limit=3,\n",
    "    logging_steps=500,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=os.getenv('WANDB_NAME'),\n",
    "\n",
    "    load_best_model_at_end=True, # 如果设置为 True，在训练结束时加载根据评估器确定的最佳模型. defaults to `False`\n",
    "    metric_for_best_model='eval_loss',   # 和 `load_best_model_at_end`联合使用，模型对比. eval_pearson_cosine\n",
    "    greater_is_better=False,    # 跟前面两个参数一起使用\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bafd6939cac426fa5e380df46b1edc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainer\n",
    " \n",
    "# trainer = SentenceTransformerTrainer(\n",
    "#     model=model,\n",
    "#     args=args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=eval_dataset,\n",
    "#     loss=losses,\n",
    "#     # evaluator=model_evaluator,\n",
    "# )\n",
    "\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=custom_dataset_train,\n",
    "    eval_dataset=custom_dataset_dev,\n",
    "    loss=mnrl_loss,\n",
    "    # evaluator=model_evaluator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training the model\n",
    "trainer.train()\n",
    "\n",
    "# save the model\n",
    "model.save_pretrained(\"./sbert-model/final\")\n",
    " \n",
    "# #  The model will be saved to the hub and the output directory\n",
    "# trainer.save_model()\n",
    "\n",
    "# # (Optional) Push it to the Hugging Face Hub\n",
    "# trainer.model.push_to_hub(os.getenv(\"WANDB_NAME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training on 4k samples took around 1 minute on an Nvidia A10G instance of [Modal labs](https://modal.com/pricing). At the time of writing (July 2024), the instance costs 1.1 USD/hour which indicates a cost of less than 0.1 USD for the training.\n",
    "\n",
    "What's pending now is the evaluation of the fine-tuned model using the 'model evaluator' from earlier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence-transformers/all-mpnet-base-v2_cosine_accuracy@1': 0.8458274398868458,\n",
       " 'sentence-transformers/all-mpnet-base-v2_cosine_accuracy@3': 0.9335219236209336,\n",
       " 'sentence-transformers/all-mpnet-base-v2_cosine_accuracy@5': 0.9476661951909476,\n",
       " 'sentence-transformers/all-mpnet-base-v2_cosine_accuracy@10': 0.9618104667609618,\n",
       " 'sentence-transformers/all-mpnet-base-v2_cosine_precision@1': np.float64(0.8458274398868458),\n",
       " 'sentence-transformers/all-mpnet-base-v2_cosine_precision@3': np.float64(0.31117397454031115),\n",
       " 'sentence-transformers/all-mpnet-base-v2_cosine_precision@5': np.float64(0.1895332390381895),\n",
       " 'sentence-transformers/all-mpnet-base-v2_cosine_precision@10': np.float64(0.09618104667609616),\n",
       " 'sentence-transformers/all-mpnet-base-v2_cosine_recall@1': np.float64(0.8458274398868458),\n",
       " 'sentence-transformers/all-mpnet-base-v2_cosine_recall@3': np.float64(0.9335219236209336),\n",
       " 'sentence-transformers/all-mpnet-base-v2_cosine_recall@5': np.float64(0.9476661951909476),\n",
       " 'sentence-transformers/all-mpnet-base-v2_cosine_recall@10': np.float64(0.9618104667609618),\n",
       " 'sentence-transformers/all-mpnet-base-v2_cosine_ndcg@10': np.float64(0.909340860295236),\n",
       " 'sentence-transformers/all-mpnet-base-v2_cosine_mrr@10': 0.8919720033227816,\n",
       " 'sentence-transformers/all-mpnet-base-v2_cosine_map@100': np.float64(0.8932635112173977)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    " \n",
    "fine_tuned_model = SentenceTransformer(\n",
    "    args.output_dir, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "from sentence_transformers import evaluation\n",
    "evaluator = evaluation.TripletEvaluator(\n",
    "    anchors=eval_dataset['custom'][\"anchor\"],\n",
    "    positives=eval_dataset['custom'][\"positive\"],\n",
    "    negatives=eval_dataset['custom'][\"negative\"],\n",
    "    name=\"all_nli_dev\",\n",
    ")\n",
    " \n",
    "fine_tuned_results = evaluator(fine_tuned_model)\n",
    "fine_tuned_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we focus on only a couple of metrics that are more relevant in our case, we get the following information:\n",
    "\n",
    "| Model | MRR@10 | NDCG@10 |\n",
    "|-------|--------|---------|\n",
    "| all-mpnet-base-v2 (Baseline) | 0.8347 | 0.8571 |\n",
    "| bge-base-en-v1.5 | 0.8965 | 0.9122 |\n",
    "| all-mpnet-base-v2 Fine-tuned | 0.8919 | 0.9093 |\n",
    "\n",
    "The fine-tuned model shows significant improvements over the baseline model, with a 6.85% increase in MRR@10 and a 6.09% increase in NDCG@10. It reached the performance level of the bge-base-en-v1.5 embeddings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Embedding models play a crucial role in the success of Retrieval-Augmented Generation (RAG) applications, as the quality of retrieved context directly impacts the generated answers. Using the Sentence Transformers 3 library, we fine-tuned the all-mpnet-base-v2 model on a biomedical question-answering dataset. The results show substantial improvements:\n",
    "\n",
    "- MRR@10 increased from 0.8347 to 0.8919 (6.85% improvement)\n",
    "- NDCG@10 improved from 0.8571 to 0.9093 (6.09% improvement)\n",
    "\n",
    "Our fine-tuned model achieved performance comparable to the more advanced bge-base-en-v1.5 model despite starting from a lower baseline.\n",
    "\n",
    "The fine-tuning process has become highly accessible and efficient. With only 4,719 question-answer pairs, we were able to achieve these improvements in approximately 1 minute of training time on an Nvidia A10G GPU. The estimated cost for this training was less than 0.1 USD, making it a cost-effective approach for enhancing domain-specific retrieval tasks.\n",
    "This shows the value of customizing embedding models for specific domains or use cases. Significant performance gains can be realized even with a relatively small dataset and minimal training time. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "agent"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
